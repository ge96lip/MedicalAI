{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc64114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a41919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19e80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for training and privacy\n",
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "\n",
    "EPOCHS = 1  #20\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4a7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make the model differentially private\n",
    "def make_private(model, optimizer, train_loader):\n",
    "    model_dp, optimizer_dp, train_loader_dp = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=EPSILON,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=MAX_GRAD_NORM,\n",
    "    )\n",
    "    return model_dp, optimizer_dp, train_loader_dp\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# Function for training the model\n",
    "def train(model, optimizer, train_loader, device, dp, task): \n",
    "    start_time = time.time()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    \n",
    "        model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        losses = []\n",
    "        accs = []\n",
    "\n",
    "        # BatchMemoryManager manages the memory usage (e.g. you can use bigger logical batches)\n",
    "        with BatchMemoryManager(data_loader=train_loader, max_physical_batch_size=128, optimizer=optimizer) as loader:\n",
    "            if not dp:\n",
    "                loader = train_loader\n",
    "\n",
    "            for i, (images, target) in enumerate(loader):   \n",
    "                optimizer.zero_grad()\n",
    "                images = images.to(device)\n",
    "                target = target.to(device)\n",
    "                \n",
    "                if task == 'multi_class': \n",
    "                    target = target.squeeze().float()\n",
    "                \n",
    "                output = model(images)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "                labels = target.detach().cpu().numpy()\n",
    "\n",
    "                acc = accuracy(preds, labels)\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                accs.append(acc)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if dp:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "            else:\n",
    "                epsilon = float('inf')\n",
    "            print(\n",
    "                f\"Training Epoch {epoch+1:02d} \\t\"\n",
    "                f\"Loss: {np.mean(losses):.6f} | \"\n",
    "                f\"Acc: {np.mean(accs) * 100:.6f} | \"\n",
    "                f\"ε = {epsilon:.2f}\"\n",
    "            )\n",
    "                \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f'\\nTraining Time \\t\\t{training_time:.2f} seconds')\n",
    "                \n",
    "# Function for testing the model\n",
    "def test(model, test_loader, device, dp, task):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            if task == 'multi_class': \n",
    "                target = target.squeeze().float()\n",
    "                \n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            \n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc)\n",
    "\n",
    "    print(\n",
    "        f\"Test Set \\t\\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} | \"\n",
    "        f\"Acc: {np.mean(accs) * 100:.6f} \"\n",
    "    )\n",
    "\n",
    "# Function for the overall pipeline\n",
    "def pipeline(model, train_loader, test_loader, device, task=None):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    # Specific layers of the model can't be made differentially private, so the model has to be fixed\n",
    "    model_fixed = ModuleValidator.fix(model)\n",
    "    optimizer_fixed = optim.RMSprop(model_fixed.parameters(), lr=LR)\n",
    "\n",
    "    model_dp, optimizer_dp, train_loader_dp = make_private(model_fixed, optimizer_fixed, train_loader)\n",
    "    \n",
    "    print(f'\\n===== With DP =====')\n",
    "    train(model_dp, optimizer_dp, train_loader_dp, device, True, task)\n",
    "    test(model_dp, test_loader, device, True, task)\n",
    "    print(f'\\n===== Without DP =====')\n",
    "    train(model, optimizer, train_loader, device, False, task)\n",
    "    test(model, test_loader, device, False, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd3e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "===== With DP =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5f957cdaee4b099fc66dab4cfecf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 01 \tLoss: 2.044835 | Acc: 29.813140 | ε = 15.40\n",
      "Training Epoch 02 \tLoss: 1.731952 | Acc: 44.228565 | ε = 18.97\n",
      "Training Epoch 03 \tLoss: 1.744378 | Acc: 47.843522 | ε = 21.78\n",
      "Training Epoch 04 \tLoss: 1.725699 | Acc: 49.884614 | ε = 24.21\n",
      "Training Epoch 05 \tLoss: 1.716553 | Acc: 51.629311 | ε = 26.40\n",
      "Training Epoch 06 \tLoss: 1.690524 | Acc: 53.580725 | ε = 28.43\n",
      "Training Epoch 07 \tLoss: 1.707080 | Acc: 54.283086 | ε = 30.34\n",
      "Training Epoch 08 \tLoss: 1.673652 | Acc: 55.519441 | ε = 32.14\n",
      "Training Epoch 09 \tLoss: 1.690878 | Acc: 55.878178 | ε = 33.87\n",
      "Training Epoch 10 \tLoss: 1.661158 | Acc: 56.794265 | ε = 35.54\n",
      "Training Epoch 11 \tLoss: 1.664296 | Acc: 57.527864 | ε = 37.14\n",
      "Training Epoch 12 \tLoss: 1.645446 | Acc: 58.255640 | ε = 38.70\n",
      "Training Epoch 13 \tLoss: 1.658301 | Acc: 58.339165 | ε = 40.22\n",
      "Training Epoch 14 \tLoss: 1.642412 | Acc: 59.203316 | ε = 41.70\n",
      "Training Epoch 15 \tLoss: 1.640699 | Acc: 59.127673 | ε = 43.15\n",
      "Training Epoch 16 \tLoss: 1.618777 | Acc: 60.014105 | ε = 44.57\n",
      "Training Epoch 17 \tLoss: 1.636385 | Acc: 60.179535 | ε = 45.96\n",
      "Training Epoch 18 \tLoss: 1.633938 | Acc: 60.412793 | ε = 47.32\n",
      "Training Epoch 19 \tLoss: 1.619277 | Acc: 61.105018 | ε = 48.67\n",
      "Training Epoch 20 \tLoss: 1.610806 | Acc: 61.119620 | ε = 49.99\n",
      "\n",
      "Training Time \t\t28201.90 seconds\n",
      "Test Set \t\tLoss: 1.774422 | Acc: 58.056641 \n",
      "\n",
      "===== Without DP =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf54608c2e84151a02edb9592e8d167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 01 \tLoss: 1.555629 | Acc: 44.900351 | ε = inf\n",
      "Training Epoch 02 \tLoss: 1.050227 | Acc: 62.592474 | ε = inf\n",
      "Training Epoch 03 \tLoss: 0.841995 | Acc: 70.547672 | ε = inf\n",
      "Training Epoch 04 \tLoss: 0.693986 | Acc: 75.778460 | ε = inf\n",
      "Training Epoch 05 \tLoss: 0.571016 | Acc: 80.101642 | ε = inf\n",
      "Training Epoch 06 \tLoss: 0.463993 | Acc: 83.962054 | ε = inf\n",
      "Training Epoch 07 \tLoss: 0.368484 | Acc: 87.204241 | ε = inf\n",
      "Training Epoch 08 \tLoss: 0.285049 | Acc: 90.141901 | ε = inf\n",
      "Training Epoch 09 \tLoss: 0.226170 | Acc: 92.120536 | ε = inf\n",
      "Training Epoch 10 \tLoss: 0.184158 | Acc: 93.557079 | ε = inf\n",
      "Training Epoch 11 \tLoss: 0.150194 | Acc: 94.693080 | ε = inf\n",
      "Training Epoch 12 \tLoss: 0.132126 | Acc: 95.380261 | ε = inf\n",
      "Training Epoch 13 \tLoss: 0.116747 | Acc: 96.020807 | ε = inf\n",
      "Training Epoch 14 \tLoss: 0.109167 | Acc: 96.247608 | ε = inf\n",
      "Training Epoch 15 \tLoss: 0.089109 | Acc: 96.926419 | ε = inf\n",
      "Training Epoch 16 \tLoss: 0.085142 | Acc: 96.988202 | ε = inf\n",
      "Training Epoch 17 \tLoss: 0.084722 | Acc: 97.091040 | ε = inf\n",
      "Training Epoch 18 \tLoss: 0.073767 | Acc: 97.398756 | ε = inf\n",
      "Training Epoch 19 \tLoss: 0.068953 | Acc: 97.623166 | ε = inf\n",
      "Training Epoch 20 \tLoss: 0.067824 | Acc: 97.636719 | ε = inf\n",
      "\n",
      "Training Time \t\t385.38 seconds\n",
      "Test Set \t\tLoss: 1.517834 | Acc: 72.080078 \n"
     ]
    }
   ],
   "source": [
    "# CIFAR 10\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='/Users/valentinbiller/Downloads/data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='/Users/valentinbiller/Downloads/data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Initialize the privacy engine and the model\n",
    "privacy_engine = PrivacyEngine()\n",
    "model = torchvision.models.resnet18(num_classes=10)\n",
    "\n",
    "pipeline(model, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "root = '/Users/valentinbiller/Downloads/'\n",
    "datasets = ['dermamnist', 'pneumoniamnist', 'retinamnist', 'bloodmnist', 'organcmnist']\n",
    "\n",
    "transformMedMNIST = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "])\n",
    "\n",
    "for data_flag in datasets:\n",
    "    \n",
    "    info = INFO[data_flag]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    \n",
    "    train_dataset = DataClass(split='train', transform=transformMedMNIST, download=True, root=root)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    test_dataset = DataClass(split='test', transform=transformMedMNIST, download=True, root=root)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    num_classes = len(info['label'])\n",
    "    \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model = torchvision.models.resnet18(num_classes=num_classes)\n",
    "    if data_flag == 'pneumoniamnist' or data_flag == 'organcmnist':     \n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    " \n",
    "    print(f'\\n\\n\\n ========== {data_flag} ========== \\n')\n",
    "    pipeline(model, train_loader, test_loader, device, task='multi_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d324b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

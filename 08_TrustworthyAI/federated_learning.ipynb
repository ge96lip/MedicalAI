{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q flwr\n",
    "# !pip install -U ipywidgets\n",
    "# !pip install -U flwr[\"simulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "import torch\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "# from typing import List, Tuple\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import flwr as fl\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from flwr.common import Metrics\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(batch_size=64):\n",
    "#     data_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[.5], std=[.5])\n",
    "#     ])\n",
    "#     data_flag = 'chestmnist'\n",
    "#     info = INFO[data_flag]\n",
    "#     DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "#     train_set = DataClass(split='train', transform=data_transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "#     test_set = DataClass(split='test', transform=data_transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "#     # val_set = DataClass(split='val', transform=data_transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "    \n",
    "#     train_loader = data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "#     test_loader = data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "#     # valid_loader = data.DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     num_examples = {\"trainset\" : len(train_set), \"testset\" : len(test_set)}\n",
    "#     return train_loader, test_loader, num_examples\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[.5], std=[.5])\n",
    "    ])\n",
    "    # transform = transforms.Compose(\n",
    "    #     [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    # )\n",
    "    data_flag = 'chestmnist'\n",
    "    info = INFO[data_flag]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    trainset = DataClass(split='train', transform=transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "    testset = DataClass(split='test', transform=transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "    valset = DataClass(split='val', transform=transform, target_transform=Lambda(lambda y: y[0]), download=True)\n",
    "\n",
    "    #  Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    if partition_size * num_clients == len(valset):\n",
    "        lengths = [partition_size] * num_clients \n",
    "    else: \n",
    "         lengths = [partition_size] * (num_clients-1)  + [partition_size+ (len(trainset) % num_clients)]\n",
    "    train_datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "    \n",
    "    partition_size = len(valset) // num_clients\n",
    "    if partition_size * num_clients == len(valset):\n",
    "        lengths = [partition_size] * num_clients \n",
    "    else: \n",
    "         lengths = [partition_size] * (num_clients-1)  + [partition_size+ (len(valset) % num_clients)]\n",
    "    # print(len(valset), lengths)\n",
    "    val_datasets = random_split(valset, lengths, torch.Generator().manual_seed(42))\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "\n",
    "    for t_ds in train_datasets:\n",
    "        # len_train = len(t_ds) \n",
    "        # t_lengths = [len_train]\n",
    "        # ds_train = random_split(t_ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(t_ds, batch_size=32, shuffle=True))\n",
    "\n",
    "\n",
    "    for v_ds in val_datasets:\n",
    "        # len_val = len(v_ds) // 10  # 10 % validation set\n",
    "        # v_lengths = [len_val]\n",
    "        # ds_val = random_split(v_ds, lengths, torch.Generator().manual_seed(42))\n",
    "        valloaders.append(DataLoader(v_ds, batch_size=32))\n",
    "        \n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "\n",
    "    net.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "    accuracy, loss = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for i, batch in enumerate(trainloader):\n",
    "            # print(i)\n",
    "            images, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            images = images.expand(-1, 3, -1, -1)\n",
    "            outputs = net(images)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            predicted = torch.argmax(outputs.detach().cpu(), axis=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        # if verbose:\n",
    "        # print(f\"Epoch {epoch}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "    return epoch_loss, epoch_acc \n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch\n",
    "            images = images.expand(-1, 3, -1, -1)\n",
    "            labels = labels.long()\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            # print(outputs)\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = torch.argmax(outputs.detach().cpu(), axis=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 14)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(6 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 14)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 6 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        # x = F.softmax(x)\n",
    "        return x\n",
    "# Load model and data\n",
    "# net = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MedmnistClient(fl.client.NumPyClient):\n",
    "#     def get_parameters(self, config):\n",
    "#         return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "#     def set_parameters(self, parameters):\n",
    "#         params_dict = zip(model.state_dict().keys(), parameters)\n",
    "#         state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "#         model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "#     def fit(self, parameters, config):\n",
    "#         self.set_parameters(parameters)\n",
    "#         train(model, train_loader, epochs=1)\n",
    "#         return self.get_parameters(config={}), num_examples[\"trainset\"], {}\n",
    "\n",
    "#     def evaluate(self, parameters, config):\n",
    "#         self.set_parameters(parameters)\n",
    "#         loss, accuracy = test(model, test_loader)\n",
    "#         return float(loss), num_examples[\"testset\"], {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {\"loss\": float(loss), \"accuracy\": float(accuracy)}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"loss\": float(loss), \"accuracy\": float(accuracy)}\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    # net = models.resnet18(weights='DEFAULT').to(DEVICE)\n",
    "    net = Net().to(DEVICE)\n",
    "    # net = Net2().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    # print(metrics)\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `evaluate` function will be by Flower called after every round\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: fl.common.NDArrays,\n",
    "    config: Dict[str, fl.common.Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net().to(DEVICE)\n",
    "    # net = Net2().to(DEVICE)\n",
    "    # valloader = valloaders[0]\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server: \n",
    "# round 1 :\n",
    "#     client 1 \n",
    "#     get parameters --> fit --> evaluate --> send the parameters back to the server \n",
    "#     client 2 (fit, evaluate) valloader[1] distributed\n",
    "#     get parameters --> fit --> evaluate --> send the parameters back to the server \n",
    "#     client 3 (fit, evaluate) \n",
    "#     get parameters --> fit --> evaluate --> send the parameters back to the server \n",
    "#     evaluate at server (centralized)\n",
    "#     use the parameters trained on client 1,2,3 and only evaluate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\Sama\\.medmnist\\chestmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Sama\\.medmnist\\chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-01-20 09:57:51,853 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=6, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\Sama\\.medmnist\\chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 09:57:57,165\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-01-20 09:58:01,433 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 1684896153.0, 'memory': 3369792308.0, 'node:127.0.0.1': 1.0, 'CPU': 16.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-01-20 09:58:01,434 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-01-20 09:58:01,435 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
      "INFO flwr 2024-01-20 09:58:01,436 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "INFO flwr 2024-01-20 09:58:01,453 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 16 actors\n",
      "INFO flwr 2024-01-20 09:58:01,455 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-01-20 09:58:01,455 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-01-20 09:58:10,461 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-01-20 09:58:10,461 | server.py:91 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=9244)\u001b[0m [Client 1] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-01-20 09:58:17,148 | server.py:94 | initial parameters (loss, other metrics): 0.0801923838598285, {'accuracy': 0.34912851602549816}\n",
      "INFO flwr 2024-01-20 09:58:17,149 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-01-20 09:58:17,149 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.0801923838598285 / accuracy 0.34912851602549816\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9244)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13816)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:58:35,103 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2024-01-20 09:58:35,106 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2024-01-20 09:58:41,664 | server.py:125 | fit progress: (1, 0.010402049225472854, {'accuracy': 0.8921232113404359}, 24.514270399999987)\n",
      "DEBUG flwr 2024-01-20 09:58:41,665 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.010402049225472854 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:58:43,032 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-20 09:58:43,033 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.010091576069011883, 'accuracy': 0.8973536487570168}), (117, {'loss': 0.009977690686226911, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.009323701953929387, 'accuracy': 0.9069269858250869})]\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9244)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:58:56,947 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 09:59:03,501 | server.py:125 | fit progress: (2, 0.010039015498444234, {'accuracy': 0.8921232113404359}, 46.35087370000008)\n",
      "DEBUG flwr 2024-01-20 09:59:03,502 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.010039015498444234 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:59:04,916 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-20 09:59:04,917 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.009596982461209283, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.008998487956720293, 'accuracy': 0.9069269858250869}), (117, {'loss': 0.009752945621457848, 'accuracy': 0.8973536487570168})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:59:18,919 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 09:59:25,445 | server.py:125 | fit progress: (3, 0.009903255271347272, {'accuracy': 0.8921232113404359}, 68.29563230000008)\n",
      "DEBUG flwr 2024-01-20 09:59:25,446 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.009903255271347272 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9244)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:59:26,846 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-20 09:59:26,847 | server.py:222 | fit_round 4: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.009458295907302157, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.009632439273654762, 'accuracy': 0.8973536487570168}), (117, {'loss': 0.008959055229858078, 'accuracy': 0.9069269858250869})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:59:41,115 | server.py:236 | fit_round 4 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 09:59:48,181 | server.py:125 | fit progress: (4, 0.009821035031999624, {'accuracy': 0.8921232113404359}, 91.03159089999997)\n",
      "DEBUG flwr 2024-01-20 09:59:48,182 | server.py:173 | evaluate_round 4: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.009821035031999624 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 09:59:49,597 | server.py:187 | evaluate_round 4 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-20 09:59:49,598 | server.py:222 | fit_round 5: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.008894680314489341, 'accuracy': 0.9069269858250869}), (117, {'loss': 0.009374849914739272, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.009552979568481062, 'accuracy': 0.8973536487570168})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 10:00:07,688 | server.py:236 | fit_round 5 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 10:00:15,527 | server.py:125 | fit progress: (5, 0.009775383428907563, {'accuracy': 0.8921232113404359}, 118.37667250000004)\n",
      "DEBUG flwr 2024-01-20 10:00:15,528 | server.py:173 | evaluate_round 5: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.009775383428907563 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9244)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 10:00:17,526 | server.py:187 | evaluate_round 5 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-20 10:00:17,527 | server.py:222 | fit_round 6: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.009334360221692284, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.008835238355004427, 'accuracy': 0.9069269858250869}), (117, {'loss': 0.009484968509896495, 'accuracy': 0.8973536487570168})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 10:00:34,225 | server.py:236 | fit_round 6 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 10:00:41,829 | server.py:125 | fit progress: (6, 0.00976011572624982, {'accuracy': 0.8921232113404359}, 144.67881750000004)\n",
      "DEBUG flwr 2024-01-20 10:00:41,830 | server.py:173 | evaluate_round 6: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.00976011572624982 / accuracy 0.8921232113404359\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7672)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-01-20 10:00:43,498 | server.py:187 | evaluate_round 6 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-20 10:00:43,498 | server.py:153 | FL finished in 146.3488069000001\n",
      "INFO flwr 2024-01-20 10:00:43,500 | app.py:226 | app_fit: losses_distributed [(1, 0.009797656236389393), (2, 0.009449472013129142), (3, 0.009349930136938332), (4, 0.009274169932569892), (5, 0.009218189028864402), (6, 0.009211135135582745)]\n",
      "INFO flwr 2024-01-20 10:00:43,500 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-01-20 10:00:43,501 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.9002590079970121), (2, 0.9002590079970121), (3, 0.9002590079970121), (4, 0.9002590079970121), (5, 0.9002590079970121), (6, 0.9002590079970121)]}\n",
      "INFO flwr 2024-01-20 10:00:43,502 | app.py:229 | app_fit: losses_centralized [(0, 0.0801923838598285), (1, 0.010402049225472854), (2, 0.010039015498444234), (3, 0.009903255271347272), (4, 0.009821035031999624), (5, 0.009775383428907563), (6, 0.00976011572624982)]\n",
      "INFO flwr 2024-01-20 10:00:43,502 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.34912851602549816), (1, 0.8921232113404359), (2, 0.8921232113404359), (3, 0.8921232113404359), (4, 0.8921232113404359), (5, 0.8921232113404359), (6, 0.8921232113404359)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117, {'loss': 0.009330596168049519, 'accuracy': 0.8964963894089328}), (117, {'loss': 0.008815586138501719, 'accuracy': 0.9069269858250869}), (117, {'loss': 0.009487223100196993, 'accuracy': 0.8973536487570168})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.009797656236389393\n",
       "\tround 2: 0.009449472013129142\n",
       "\tround 3: 0.009349930136938332\n",
       "\tround 4: 0.009274169932569892\n",
       "\tround 5: 0.009218189028864402\n",
       "\tround 6: 0.009211135135582745\n",
       "History (loss, centralized):\n",
       "\tround 0: 0.0801923838598285\n",
       "\tround 1: 0.010402049225472854\n",
       "\tround 2: 0.010039015498444234\n",
       "\tround 3: 0.009903255271347272\n",
       "\tround 4: 0.009821035031999624\n",
       "\tround 5: 0.009775383428907563\n",
       "\tround 6: 0.00976011572624982\n",
       "History (metrics, distributed, evaluate):\n",
       "{'accuracy': [(1, 0.9002590079970121), (2, 0.9002590079970121), (3, 0.9002590079970121), (4, 0.9002590079970121), (5, 0.9002590079970121), (6, 0.9002590079970121)]}History (metrics, centralized):\n",
       "{'accuracy': [(0, 0.34912851602549816), (1, 0.8921232113404359), (2, 0.8921232113404359), (3, 0.8921232113404359), (4, 0.8921232113404359), (5, 0.8921232113404359), (6, 0.8921232113404359)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "NUM_CLIENTS = 3\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n",
    "# params = get_parameters(models.resnet18(weights='DEFAULT'))\n",
    "# params = get_parameters(Net())\n",
    "server_config = fl.server.ServerConfig(num_rounds=6)\n",
    "# Pass parameters to the Strategy for server-side parameter initialization\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=1.0,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_evaluate_clients=NUM_CLIENTS,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    # initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    "    evaluate_metrics_aggregation_fn=weighted_average, \n",
    "    # fit_metrics_aggregation_fn=weighted_average\n",
    "    evaluate_fn=evaluate\n",
    "    \n",
    ")\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=server_config,  \n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# train(model , trainloaders[0], epochs=3)\n",
    "# loss, accuracy = test(model, valloaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl.client.start_numpy_client(server_address=\"[::]:8080\", client=MedmnistClient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIM_EX1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
